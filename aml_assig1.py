# -*- coding: utf-8 -*-
"""aml_assig1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kna_v-MTOgJb84PikqZ1HGsIi7oBKTtQ

$\qquad$ $\qquad$$\qquad$  **DAT340/DIT886 Applied Machine Learning: Programming Assignment 1 -- Introductory Tour and Decision Trees** <br />
$\qquad$ $\qquad$$\qquad$                     **Chalmers University of Technology** <br />
$\qquad$ $\qquad$$\qquad$                     **Due Date: 25th January 2021** <br />

# Task 1: A classification example: fetal heart condition diagnosis

### Step 1: Reading the data
"""

## download file 
import requests

ctg_url = 'http://www.cse.chalmers.se/~richajo/dit866/data/CTG.csv'
r = requests.get(ctg_url)
ctg_file = "/content/GTG.csv"

with open(ctg_file, 'wb') as f:
    f.write(r.content)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import cross_val_score
  
# Read the CSV file.
data = pd.read_csv(ctg_file, skiprows=1)

# Select the relevant numerical columns.
selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',
                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',
                 'Median', 'Variance', 'Tendency', 'NSP']
data = data[selected_cols].dropna()

# Shuffle the dataset.
data_shuffled = data.sample(frac=1.0, random_state=0)

# Split into input part X and output part Y.
X = data_shuffled.drop('NSP', axis=1)

# Map the diagnosis code to a human-readable label.
def to_label(y):
    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]

Y = data_shuffled['NSP'].apply(to_label)

# Partition the data into training and test sets.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)

"""### Step 2: Training the baseline classifier"""

# DummyClassifier
clf = DummyClassifier(strategy='most_frequent')
cross_val_score(clf, Xtrain, Ytrain)

"""### Step 3: Trying out some different classifiers"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

from sklearn.linear_model import Perceptron
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

import numpy as np

# Tree-based classifiers:
clf_dtc = DecisionTreeClassifier(random_state=0)
cvs_dtc = cross_val_score(clf_dtc, Xtrain, Ytrain)
print('dtc: {}'.format(np.mean(cvs_dtc)))

clf_rfc = RandomForestClassifier(random_state=0)
cvs_rfc = cross_val_score(clf_rfc, Xtrain, Ytrain)
print('rfc: {}'.format(np.mean(cvs_rfc)))

clf_gbc = GradientBoostingClassifier(random_state=0)
cvs_gbc = cross_val_score(clf_gbc, Xtrain, Ytrain)
print('gbc: {}'.format(np.mean(cvs_gbc)))

#Linear classifiers:
clf_p = Perceptron(random_state=0)
cvs_p = cross_val_score(clf_p, Xtrain, Ytrain)
print('p: {}'.format(np.mean(cvs_p)))


clf_lr = LogisticRegression(random_state=0)
cvs_lr = cross_val_score(clf_lr, Xtrain, Ytrain)
print('lr: {}'.format(np.mean(cvs_lr)))

clf_lsvc = LinearSVC(random_state=0)
cvs_lvsc = cross_val_score(clf_lsvc, Xtrain, Ytrain)
print('lsvc: {}'.format(np.mean(cvs_lvsc)))

# Neural network classifier (will take longer time to train):
clf_mlpc = MLPClassifier(random_state=0)
cvs_mlpc = cross_val_score(clf_mlpc, Xtrain, Ytrain)
print('mlpc: {}'.format(np.mean(cvs_mlpc)))

"""The following table shows the average accuracy of the different folds in cross-validation: 


| Model  |   |  Accuracy score |
|:---     |---|---:|
| DecisionTreeClassifier  |   | 0.924 |
| RandomForestClassifier  |   |  0.943 |
| GradientBoostingClassifier  |   | 0.949  |
| Perceptron  |   | 0.825  |
| LogisticRegression  |   | 0.874 |
| LinearSVC  |   | 0.857  |
| MLPClassifier  |   | 0.885  |
|   |   |   |

As can be seen in the table, the GradientBoostingClassifier has the highest cross-validation accuracy, and we will therefore evaluate that model on the test data.

### Step 4: Final evaluation
"""

clf_gbc.fit(Xtrain, Ytrain)
Yguess = clf_gbc.predict(Xtest)
print("Accuracy: {}".format(accuracy_score(Ytest, Yguess)))

"""# Task 2: Decision trees for classification 

"""

class DecisionTreeLeaf:

    def __init__(self, value):
        self.value = value

    # This method computes the prediction for this leaf node. This will just return a constant value.
    def predict(self, x):
        return self.value

    # Utility function to draw a tree visually using graphviz.
    def draw_tree(self, graph, node_counter, names):
        node_id = str(node_counter)
        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)
        graph.node(node_id, val_str, style='filled')
        return node_counter+1, node_id
        
    def __eq__(self, other):
        if isinstance(other, DecisionTreeLeaf):
            return self.value == other.value
        else:
            return False

class DecisionTreeBranch:

    def __init__(self, feature, threshold, low_subtree, high_subtree):
        self.feature = feature
        self.threshold = threshold
        self.low_subtree = low_subtree
        self.high_subtree = high_subtree

    # For a branch node, we compute the prediction by first considering the feature, and then 
    # calling the upper or lower subtree, depending on whether the feature is or isn't greater
    # than the threshold.
    def predict(self, x):
        if x[self.feature] <= self.threshold:
            return self.low_subtree.predict(x)
        else:
            return self.high_subtree.predict(x)

    # Utility function to draw a tree visually using graphviz.
    def draw_tree(self, graph, node_counter, names):
        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)
        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)
        node_id = str(node_counter)
        fname = f'F{self.feature}' if names is None else names[self.feature]
        lbl = f'{fname} > {self.threshold:.4g}?'
        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')
        graph.edge(node_id, low_id, 'False')
        graph.edge(node_id, high_id, 'True')
        return node_counter+1, node_id

from graphviz import Digraph
from sklearn.base import BaseEstimator, ClassifierMixin
from abc import ABC, abstractmethod

class DecisionTree(ABC, BaseEstimator):

    def __init__(self, max_depth):
        super().__init__()
        self.max_depth = max_depth
        
    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that
    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method
    # called make_tree (see below).
    def fit(self, X, Y):
        if isinstance(X, pd.DataFrame):
            self.names = X.columns
            X = X.to_numpy()
        elif isinstance(X, list):
            self.names = None
            X = np.array(X)
        else:
            self.names = None
        Y = np.array(Y)        
        self.root = self.make_tree(X, Y, self.max_depth)
        
    def draw_tree(self):
        graph = Digraph()
        self.root.draw_tree(graph, 0, self.names)
        return graph
    
    # By scikit-learn convention, the method *predict* computes the classification or regression output
    # for a set of instances.
    # To implement it, we call a separate method that carries out the prediction for one instance.
    def predict(self, X):
        if isinstance(X, pd.DataFrame):
            X = X.to_numpy()
        return [self.predict_one(x) for x in X]

    # Predicting the output for one instance.
    def predict_one(self, x):
        return self.root.predict(x)        

    # This is the recursive training 
    def make_tree(self, X, Y, max_depth):

        # We start by computing the default value that will be used if we'll return a leaf node.
        # For classifiers, this will be the most common value in Y.
        default_value = self.get_default_value(Y)

        # First the two base cases in the recursion: is the training set completely
        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.

        # If we have reached the maximum depth, return a leaf with the majority value.
        if max_depth == 0:
            return DecisionTreeLeaf(default_value)

        # If all the instances in the remaining training set have the same output value,
        # return a leaf with this value.
        if self.is_homogeneous(Y):
            return DecisionTreeLeaf(default_value)

        # Select the "most useful" feature and split threshold. To rank the "usefulness" of features,
        # we use one of the classification or regression criteria.
        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.
        n_features = X.shape[1]
        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))
        
        if best_feature is None:
            return DecisionTreeLeaf(default_value)

        # Split the training set into subgroups, based on whether the selected feature is greater than
        # the threshold or not
        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)

        # Build the subtrees using a recursive call. Each subtree is associated
        # with a value of the feature.
        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)
        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)

        if low_subtree == high_subtree:
            return low_subtree

        # Return a decision tree branch containing the result.
        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)
    
    # Utility method that splits the data into the "upper" and "lower" part, based on a feature
    # and a threshold.
    def split_by_feature(self, X, Y, feature, threshold):
        low = X[:,feature] <= threshold
        high = ~low
        return X[low], X[high], Y[low], Y[high]
    
    # The following three methods need to be implemented by the classification and regression subclasses.
    
    @abstractmethod
    def get_default_value(self, Y):
        pass

    @abstractmethod
    def is_homogeneous(self, Y):
        pass

    @abstractmethod
    def best_split(self, X, Y, feature):
        pass

from collections import Counter

class TreeClassifier(DecisionTree, ClassifierMixin):

    def __init__(self, max_depth=10, criterion='maj_sum'):
        super().__init__(max_depth)
        self.criterion = criterion
        
    def fit(self, X, Y):
        # For decision tree classifiers, there are some different ways to measure
        # the homogeneity of subsets.
        if self.criterion == 'maj_sum':
            self.criterion_function = majority_sum_scorer
        elif self.criterion == 'info_gain':
            self.criterion_function = info_gain_scorer
        elif self.criterion == 'gini':
            self.criterion_function = gini_scorer
        else:
            raise Exception(f'Unknown criterion: {self.criterion}')
        super().fit(X, Y)
        self.classes_ = sorted(set(Y))

    # Select a default value that is going to be used if we decide to make a leaf.
    # We will select the most common value.
    def get_default_value(self, Y):
        self.class_distribution = Counter(Y)
        return self.class_distribution.most_common(1)[0][0]
    
    # Checks whether a set of output values is homogeneous. In the classification case, 
    # this means that all output values are identical.
    # We assume that we called get_default_value just before, so that we can access
    # the class_distribution attribute. If the class distribution contains just one item,
    # this means that the set is homogeneous.
    def is_homogeneous(self, Y):
        return len(self.class_distribution) == 1
        
    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)
    # for the upper and lower parts, and then compute the impurity criterion using these tables.
    # In the end, we return a triple consisting of
    # - the best score we found, according to the criterion we're using
    # - the id of the feature
    # - the threshold for the best split
    def best_split(self, X, Y, feature):

        # Create a list of input-output pairs, where we have sorted
        # in ascending order by the input feature we're considering.
        sorted_indices = np.argsort(X[:, feature])        
        X_sorted = list(X[sorted_indices, feature])
        Y_sorted = list(Y[sorted_indices])

        n = len(Y)

        # The frequency tables corresponding to the parts *before and including*
        # and *after* the current element.
        low_distr = Counter()
        high_distr = Counter(Y)

        # Keep track of the best result we've seen so far.
        max_score = -np.inf
        max_i = None

        # Go through all the positions (excluding the last position).
        for i in range(0, n-1):

            # Input and output at the current position.
            y_i = Y_sorted[i]
            x_i = X_sorted[i]
            
            # Update the frequency tables.
            low_distr[y_i] += 1
            high_distr[y_i] -= 1

            # If the input is equal to the input at the next position, we will
            # not consider a split here.
            #x_next = XY[i+1][0]
            x_next = X_sorted[i+1]
            if x_i == x_next:
                continue

            # Compute the homogeneity criterion for a split at this position.
            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)

            # If this is the best split, remember it.
            if score > max_score:
                max_score = score
                max_i = i

        # If we didn't find any split (meaning that all inputs are identical), return
        # a dummy value.
        if max_i is None:
            return -np.inf, None, None

        # Otherwise, return the best split we found and its score.
        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])
        return max_score, feature, split_point

def majority_sum_scorer(n_low, low_distr, n_high, high_distr):
    maj_sum_low = low_distr.most_common(1)[0][1]
    maj_sum_high = high_distr.most_common(1)[0][1]
    return maj_sum_low + maj_sum_high
    
def entropy(distr):
    n = sum(distr.values())
    ps = [n_i/n for n_i in distr.values()]
    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)

def info_gain_scorer(n_low, low_distr, n_high, high_distr):
    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)

def gini_impurity(distr):
    n = sum(distr.values())
    ps = [n_i/n for n_i in distr.values()]
    return 1-sum(p**2 for p in ps)
    
def gini_scorer(n_low, low_distr, n_high, high_distr):
    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

import numpy as np

# gini
cls_gini = TreeClassifier(max_depth=4, criterion='gini')
cls_gini.fit(Xtrain,Ytrain)

# info_gain
cls_info_gain = TreeClassifier(max_depth=4, criterion='info_gain')
cls_info_gain.fit(Xtrain,Ytrain)

# maj_sum
cls_maj_sum = TreeClassifier(max_depth=4, criterion='maj_sum')
cls_maj_sum.fit(Xtrain,Ytrain)


cv_gini = cross_val_score(cls_gini, Xtrain, Ytrain)
cv_info_gain = cross_val_score(cls_info_gain, Xtrain, Ytrain)
cv_maj_sum = cross_val_score(cls_maj_sum, Xtrain, Ytrain)

print('gini', np.mean(cv_gini))
print('info_gain', np.mean(cv_info_gain))
print('maj_sum', np.mean(cv_maj_sum))

import matplotlib.pyplot as plt
import seaborn as sns

depth_accuracy_list_train = {}
depth_accuracy_list_test = {}

dummy_value = -1

for criterion in ["gini","info_gain","maj_sum"]:
  depth_accuracy_list_test[criterion] = []
  depth_accuracy_list_train[criterion] = []
  for max_depth in np.arange(0,20):
    cls = TreeClassifier(max_depth=max_depth, criterion=criterion)
    cls.fit(Xtrain,Ytrain)
    cv = np.mean(cross_val_score(cls,Xtrain,Ytrain))

    depth_accuracy_list_train[criterion].append(cv)

    Yguess = cls.predict(Xtest)
    depth_accuracy_list_test[criterion].append(np.mean(accuracy_score(Ytest, Yguess)))

print(depth_accuracy_list_train)
print(depth_accuracy_list_test)

for criterion in ["gini","info_gain","maj_sum"]:
  train = plt.plot(np.arange(0,20),depth_accuracy_list_train[criterion], label="Train")
  test = plt.plot(np.arange(0,20),depth_accuracy_list_test[criterion], label="Test")
  plt.xticks(np.arange(0,20))
  plt.yticks(np.arange(0.75,1.01,step=0.05))
  plt.legend()
  plt.title(criterion)
  plt.xlabel("Max_depth")
  plt.ylabel("Accuracy")
  plt.show()

"""To find the best criterion and max depth we find the best accuracy on the test-data:"""

best_criterion = None
best_max_depth = None
best_score = 0

for criterion in ["gini","info_gain","maj_sum"]:
  depth = np.argmax(depth_accuracy_list_train[criterion])
  score = depth_accuracy_list_train[criterion][depth]

  if score > best_score:
    best_score = score
    best_max_depth = depth
    best_criterion = criterion


print("Evaluated score on test:", depth_accuracy_list_test[best_criterion][best_max_depth])
print("best max depth:",best_max_depth)
print("best criterion", best_criterion)

"""Given the data (and our split of it) the best accuracy over the training set is with `max_depth=7` and `criterion=gini`. Such a `TreeClassifier` reaches the accuracy of `0.913` on the test-set. """

## here is a tree with max_depth 4
cls_gini.draw_tree()

"""# Task 3: A regression example: predicting apartment prices"""

import requests
sb_url = "http://www.cse.chalmers.se/~richajo/dit866/data/sberbank.csv"
r = requests.get(sb_url)
sb_file = "/content/sberbank.csv"

with open(sb_file, 'wb') as f:
    f.write(r.content)

# Read the CSV file using Pandas.
import pandas as pd
from sklearn.model_selection import train_test_split

alldata = pd.read_csv('./sberbank.csv')

# Convert the timestamp string to an integer representing the year.
def get_year(timestamp):
    return int(timestamp[:4])
alldata['year'] = alldata.timestamp.apply(get_year)

# Select the 9 input columns and the output column.
selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']
alldata = alldata[selected_columns]
alldata = alldata.dropna()

# Shuffle.
alldata_shuffled = alldata.sample(frac=1.0, random_state=0)

# Separate the input and output columns.
X = alldata_shuffled.drop('price_doc', axis=1)
# For the output, we'll use the log of the sales price.
Y = alldata_shuffled['price_doc'].apply(np.log)

# Split into training and test sets.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)

from sklearn.dummy import DummyRegressor
from sklearn.model_selection import cross_validate
m1 = DummyRegressor()
cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')

from sklearn.model_selection import cross_validate

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

from sklearn.neural_network import MLPRegressor

import numpy as np

m2 = LinearRegression()
m2.fit(Xtrain, Ytrain)
m3 = Ridge()
m3.fit(Xtrain, Ytrain)
m4 = Lasso()
m4.fit(Xtrain, Ytrain)
m5 = DecisionTreeRegressor()
m5.fit(Xtrain, Ytrain)
m6 = RandomForestRegressor()
m6.fit(Xtrain, Ytrain)
m7 = GradientBoostingRegressor()
m7.fit(Xtrain, Ytrain)
m8 = MLPRegressor()
m8.fit(Xtrain, Ytrain)


c2 = cross_validate(m2, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c3 = cross_validate(m3, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c4 = cross_validate(m4, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c5 = cross_validate(m5, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c6 = cross_validate(m6, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c7 = cross_validate(m7, Xtrain, Ytrain, scoring='neg_mean_squared_error')
c8 = cross_validate(m8, Xtrain, Ytrain, scoring='neg_mean_squared_error')

print('c2', np.mean(c2['test_score']))
print('c3', np.mean(c3['test_score']))
print('c4', np.mean(c4['test_score']))
print('c5', np.mean(c5['test_score']))
print('c6', np.mean(c6['test_score']))
print('c7', np.mean(c7['test_score']))
print('c8', np.mean(c8['test_score']))

"""The best results were made using `GradientBoostingRegressor` and the error is roughly `-0.27`. Gradient boosting is a techique which produces a predicition model in the form of an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) of weak predicition models (decision trees). 


"""

from sklearn.metrics import mean_squared_error
clf = GradientBoostingRegressor() 
clf.fit(Xtrain, Ytrain)
mean_squared_error(Ytest, clf.predict(Xtest))

"""# Task 4: Decision trees for regression

## Boilerplate & Imports

### Imports
"""

import requests
sb_url = "http://www.cse.chalmers.se/~richajo/dit866/data/sberbank.csv"
r = requests.get(sb_url)
sb_file = "/content/sberbank.csv"

with open(sb_file, 'wb') as f:
    f.write(r.content)

# Read the CSV file using Pandas.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


alldata = pd.read_csv('./sberbank.csv')

# Convert the timestamp string to an integer representing the year.
def get_year(timestamp):
    return int(timestamp[:4])
alldata['year'] = alldata.timestamp.apply(get_year)

# Select the 9 input columns and the output column.
selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']
alldata = alldata[selected_columns]
alldata = alldata.dropna()

# Shuffle.
alldata_shuffled = alldata.sample(frac=1.0, random_state=0)

# Separate the input and output columns.
X = alldata_shuffled.drop('price_doc', axis=1)
# For the output, we'll use the log of the sales price.
Y = alldata_shuffled['price_doc'].apply(np.log)

# Split into training and test sets.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)

"""##Code

### Step 1 - Implementing the regression model
"""

from collections import Counter
from sklearn.base import RegressorMixin

class TreeRegressor(DecisionTree, RegressorMixin):

    def __init__(self, max_depth=10, variance=0.0001):
        super().__init__(max_depth)
        self.variance = variance
    

    def fit(self, X, Y):
        super().fit(X, Y)
        self.classes_ = sorted(set(Y))

    def get_default_value(self, Y):
        return np.mean(Y)
    
    def is_homogeneous(self, Y):
        return np.var(Y) < self.variance if len(Y) > 2 else True

        
    # Finds the best splitting point for a given feature.
    # In the end, we return a triple consisting of
    # - the best score we found, according to the criterion we're using
    # - the id of the feature
    # - the threshold for the best split
    def best_split(self, X, Y, feature):
        # Create a list of input-output pairs, where we have sorted
        # in ascending order by the input feature we're considering.
        sorted_indices = np.argsort(X[:, feature])        
        X_sorted = list(X[sorted_indices, feature])
        Y_sorted = list(Y[sorted_indices])

        n = len(Y)

        if n <= 2:
          return self.get_default_value(Y), None, None

        total_sum = sum(Y_sorted)
        total_sum_sq = sum([y**2 for y in Y_sorted])
        total_var = (float(1)/n) * total_sum_sq - (float(1)/(n**2))*(total_sum**2)

        # keep track of left sum and left squared sum
        left_sum = 0
        left_sum_sq = 0
        n_left = 0

        # keep track of right sum and right squared sum
        right_sum = total_sum
        right_sum_sq = total_sum_sq
        n_right = n

        # Keep track of the best result we've seen so far.
        max_score = -np.inf
        max_i = None

        # Go through all the positions (excluding the last position).
        for split_index in range(0, n-1):
            # get value of split
            value_at_split = Y_sorted[split_index]
            
            # update left values by adding
            left_sum += value_at_split
            left_sum_sq += value_at_split**2

            # update right values by subtracting
            right_sum -= value_at_split
            right_sum_sq -= value_at_split**2

            # increment and decrement total count in each sub-array
            n_left += 1
            n_right -= 1

            ## re-added after consulting with TA
            ## stops repeated questions
            x_i = X_sorted[split_index]
            x_next = X_sorted[split_index+1]
            if x_i == x_next:
                continue

            # calculate parts of variance reduction algorithm.
            left_var =  (float(1)/n_left)*left_sum_sq   - (float(1)/(n_left**2))  * (left_sum**2)
            right_var = (float(1)/n_right)*right_sum_sq - (float(1)/(n_right**2)) * (right_sum**2)

            # variance reduction algorithm
            score = total_var - (float(n_right)/n)*right_var - (float(n_left)/n)*left_var

            # If this is the best split, remember it.
            if score > max_score:
                max_score = score
                max_i = split_index
                

        # If we didn't find any split (meaning that all inputs are identical), return
        # a dummy value.
        if max_i is None:
            return self.get_default_value(Y), None, None
      
        # Otherwise, return the best split we found and its score.
        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])
        return max_score, feature, split_point

"""### Step 2 - Sanity"""

def make_some_data(n):
    x = np.random.uniform(-5, 5, size=n)
    Y = (x > 1) + 0.1*np.random.normal(size=n)
    X = x.reshape(n, 1) # X needs to be a 2-dimensional matrix
    return X, Y

# as the only indicative value of the data-generating function is Y, and only on the value 1, 
# we can assume max_depth=1. More depth would just make the model a disservice.
cls_sanity = TreeRegressor(max_depth=1, variance=0.005)
X,Y = make_some_data(50000)
cls_sanity.fit(X,Y)
plt.scatter(X,Y)

cls_sanity.draw_tree()

"""For this type of data we would want a decision tree root node with two leafs, with a split on 1. One leaf having 0 and the other having 1. This is because the data-generating function generates y based on x. If `x > 1` the value of y will be generated uniformly around 1. If `x < 1`, the value of y will be generated uniformly around 0.

### Step 3 - Predict
"""

# get a dummy model
from sklearn.dummy import DummyRegressor
from sklearn.model_selection import cross_validate
dummy = DummyRegressor()
dummy.fit(Xtrain,Ytrain)
cv_dummy = cross_validate(dummy, Xtrain, Ytrain, scoring='neg_mean_squared_error')

# train models with different max_depths
clf_train_acc = []
clf_test_acc = []

variance = 0.00001
max_depths = np.arange(0,13)


for max_depth in max_depths:
  cls_regression = TreeRegressor(max_depth=max_depth, variance=variance)
  cls_regression.fit(Xtrain,Ytrain)
  # training set
  res_obj = cross_validate(cls_regression,Xtrain,Ytrain,scoring="neg_mean_squared_error")
  clf_train_acc.append(np.mean(res_obj["test_score"]))
  
  # testing set 
  sq_error_test_score = mean_squared_error(Ytest,cls_regression.predict(Xtest))
  # remember to take negative mean_sq_err
  clf_test_acc.append(-sq_error_test_score)

## To find the best max_depth
best_max_depth = np.argmax(clf_test_acc)
best_score = clf_test_acc[best_max_depth]

print(best_score)
print(best_max_depth)

"""### Step 4 - Underfitting and overfitting"""

import matplotlib.pyplot as plt

sq_error_train = clf_train_acc
sq_error_test = clf_test_acc

# plot data
plt.plot(max_depths,sq_error_train, label="train")
plt.plot(max_depths,sq_error_test, label="test")
plt.axhline(y=np.mean(cv_dummy["test_score"]), label="dummy", color="green")

## make it look nicer
plt.xticks(max_depths)
plt.legend()
plt.title("Negative mean squared error given variance: " + str(variance))
plt.xlabel("Max_depth")
plt.ylabel("Negative mean squared error")

# show plot
plt.show()

"""Best `max_depth` is `6`, as the score on both the training and test set is the best with that hyperparameter. `-0.2862` neg_mean_squared_error. Our comment on the differences between the test and training values is that the score is always better on the `train` data-set, as it has been trained on that data. In a sense we have then overfitted, due to the `test` values not being as accurate. However, equal scores would mean that the training-data is completely representative for the test-data, which is almost impossible.

### (Extra) Comparing our Model against scikit-learn's `DecisionTreeRegressor`

By comparing our model with the corresponding sk-learn model, we see if our implementation is correct and if it differs. We will plot both models `neg_mean_squared_error` and compare the two.
"""

from sklearn.tree import DecisionTreeRegressor
clf_train_neg = []
clf_test_neg = []

# as sk-learn decisiontreeRegressor does not allow max_depth=0 we skip it
for max_depth in max_depths[1:]:
    cls_regression = DecisionTreeRegressor(max_depth=max_depth)
    cls_regression.fit(Xtrain,Ytrain)

    # training set
    res_obj = cross_validate(cls_regression,Xtrain,Ytrain,scoring="neg_mean_squared_error")
    clf_train_neg.append(np.mean(res_obj["test_score"]))
    
    # testing set 
    sq_error_test_score = mean_squared_error(Ytest,cls_regression.predict(Xtest))
    
    # remember to take negative mean_sq_err
    clf_test_neg.append(-sq_error_test_score)

# plot the scores of the two different models
## train
plt.plot(max_depths,sq_error_train, label="train custom")
plt.plot(max_depths[1:], clf_train_neg, label="train sk-learn")
## test
plt.plot(max_depths,sq_error_test, label="test custom")
plt.plot(max_depths[1:], clf_test_neg, label="test sk-learn")


plt.xticks(max_depths)
plt.legend()
plt.show()

"""It can be seen that the score is identical for `max_depth<7`, where for larger max_depths our model outperforms sk-learn. Perhaps due to optimization or different thresholds of variances in `is_homogeneous`. Nonetheless it is reassuring that very similiar results are shown, as our implementation is based on sk-learn. """